# ğŸ¤– LangGraph Documentation Chatbot

A full-stack chatbot that uses n8n for data pipeline orchestration, RAG for document retrieval, and Next.js for the UI.

## ğŸ¯ Project Overview

**What it does:**

- Ingests LangGraph documentation into a RAG system
- Provides a ChatGPT-like interface to ask questions about LangGraph
- Uses n8n workflows to orchestrate the data pipeline

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                        â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚      Next.js Chat UI (Port 3000)               â”‚     â”‚
â”‚  â”‚  - ChatGPT-like interface                      â”‚     â”‚
â”‚  â”‚  - Message history                             â”‚     â”‚
â”‚  â”‚  - Typing indicators                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ HTTP POST
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Next.js API Routes                          â”‚
â”‚  /api/chat  -  Proxies requests to n8n                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP POST
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 n8n WORKFLOWS (Port 5678)                â”‚
â”‚                                                          â”‚
â”‚  Workflow 1: Document Ingestion Pipeline                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Webhook â†’ Scrape LangGraph Docs â†’ Split   â”‚         â”‚
â”‚  â”‚ â†’ Embed â†’ Store in Vector DB â†’ Notify     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                          â”‚
â”‚  Workflow 2: Chat Query Pipeline                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Webhook â†’ Call RAG Service â†’ Format        â”‚         â”‚
â”‚  â”‚ â†’ Add Sources â†’ Return Response            â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP POST
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Python RAG Service (Port 5001)                 â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  /ingest  - Process documents            â”‚           â”‚
â”‚  â”‚  /query   - Answer questions             â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  LlamaIndex + ChromaDB                   â”‚           â”‚
â”‚  â”‚  - Semantic search                       â”‚           â”‚
â”‚  â”‚  - Context retrieval                     â”‚           â”‚
â”‚  â”‚  - Response generation                   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- Python 3.9+
- Docker (for n8n)
- OpenAI API key

### Setup (10 Minutes)

1. **Clone and Install Backend**

```bash
# Navigate to backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

2. **Install Frontend**

```bash
# Navigate to frontend
cd frontend
npm install
```

3. **Start Services**

```bash
# Terminal 1: Start RAG Service
cd backend
python rag_service.py

# Terminal 2: Start n8n
docker run -d --name n8n -p 5678:5678 -v ~/.n8n:/home/node/.n8n docker.n8n.io/n8nio/n8n

# Terminal 3: Start Next.js
cd frontend
npm run dev
```

4. **Setup n8n Workflows**

- Open http://localhost:5678
- Import workflows from `n8n-workflows/` directory
- Activate both workflows

5. **Open Application**

- Navigate to http://localhost:3000
- Start chatting about LangGraph!

## ğŸ“ Project Structure

```
langraph-docs-chatbot/
â”œâ”€â”€ backend/                      # Python RAG service
â”‚   â”œâ”€â”€ rag_service.py           # Main RAG service
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env.example            # Environment template
â”‚   â””â”€â”€ documents/              # Ingested documents
â”‚
â”œâ”€â”€ frontend/                    # Next.js application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Chat UI
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ chat/
â”‚   â”‚           â””â”€â”€ route.ts    # API route to n8n
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx   # Main chat component
â”‚   â”‚   â”œâ”€â”€ MessageList.tsx     # Message display
â”‚   â”‚   â””â”€â”€ ChatInput.tsx       # Input component
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ next.config.js
â”‚
â”œâ”€â”€ n8n-workflows/               # n8n workflow definitions
â”‚   â”œâ”€â”€ 1-document-ingestion.json
â”‚   â””â”€â”€ 2-chat-query.json
â”‚
â””â”€â”€ README.md                    # This file
```

## ğŸ“ How It Works

### Document Ingestion Flow

1. **User triggers ingestion** (manual or scheduled in n8n)
2. **n8n workflow starts:**
   - Scrapes LangGraph documentation from website
   - Cleans and extracts text content
   - Splits into chunks
   - Calls Python service `/ingest` endpoint
3. **Python RAG service:**
   - Creates embeddings using OpenAI
   - Stores in ChromaDB vector database
   - Returns success confirmation
4. **n8n completes:**
   - Logs results
   - Sends notification (optional)

### Chat Query Flow

1. **User types question** in Next.js UI
2. **Next.js sends to** `/api/chat` route
3. **API route forwards to** n8n webhook
4. **n8n workflow:**
   - Receives query
   - Calls Python service `/query` endpoint
   - Formats response
   - Adds source citations
5. **Python RAG service:**
   - Searches vector database
   - Retrieves relevant chunks
   - Generates answer with LLM
   - Returns with sources
6. **Response flows back:**
   - n8n â†’ Next.js API â†’ Frontend
   - UI displays answer with sources

## ğŸ¯ Key Features

### âœ… Full Stack

- **Frontend**: Modern Next.js 14 with TypeScript
- **Backend**: Python with LlamaIndex
- **Orchestration**: n8n for data pipelines

### âœ… n8n Data Pipeline

- Visual workflow design
- Error handling at each step
- Logging and monitoring
- Easy to modify and extend

### âœ… RAG Implementation

- Semantic search with embeddings
- Context-aware responses
- Source citations
- ChromaDB for persistence

### âœ… Production Ready

- Environment configuration
- Error handling
- Type safety (TypeScript)
- Docker support

## ğŸ”§ Configuration

### Backend (.env)

```env
OPENAI_API_KEY=your_key_here
```

### Frontend (.env.local)

```env
N8N_WEBHOOK_URL=http://localhost:5678/webhook/chat
```

### n8n

- Import workflows from `n8n-workflows/`
- Configure webhook URLs
- Set OpenAI credentials if needed

## ğŸ§ª Testing

### Test RAG Service

```bash
# Test ingestion
curl -X POST http://localhost:5001/ingest \
  -H "Content-Type: application/json" \
  -d '{"url": "https://docs.langchain.com/oss/python/langgraph/overview"}'

# Test query
curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is LangGraph?"}'
```

### Test n8n Workflows

1. Open n8n at http://localhost:5678
2. Open each workflow
3. Click "Execute Workflow" to test

### Test Full Flow

1. Open http://localhost:3000
2. Type: "What is LangGraph?"
3. Verify you get a response with sources

## ğŸš€ Next Steps

### Enhancements I Could Add

1. Conversation memory
2. Streaming responses
3. Document upload via UI
4. Admin dashboard
5. User authentication

## ğŸ“ License

MIT
